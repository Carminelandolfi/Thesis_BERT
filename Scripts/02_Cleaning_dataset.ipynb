{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60e384c9-9ecf-4747-900a-0d865d50b6ce",
   "metadata": {
    "id": "60e384c9-9ecf-4747-900a-0d865d50b6ce"
   },
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00763811-3173-4ed8-98a3-25c0a15ae9e1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "00763811-3173-4ed8-98a3-25c0a15ae9e1",
    "outputId": "c231d1e5-322c-4951-cb02-94a6bf125ca1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "from pylatexenc.latex2text import LatexNodes2Text\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d04b4cc-db07-4652-b9d2-65ba92b0c36a",
   "metadata": {
    "id": "5d04b4cc-db07-4652-b9d2-65ba92b0c36a"
   },
   "source": [
    "# Update Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88dad50-a659-4d08-9de1-83f33d9e8e18",
   "metadata": {
    "id": "e88dad50-a659-4d08-9de1-83f33d9e8e18"
   },
   "outputs": [],
   "source": [
    "url = '../Dataset/cs_papers_api.csv'\n",
    "# Load the dataset from CSV file\n",
    "\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4a974c-0f57-4756-8fdf-ef58097c6da1",
   "metadata": {
    "id": "dc4a974c-0f57-4756-8fdf-ef58097c6da1"
   },
   "source": [
    "# Cleaning of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f88c4cb-5512-4628-b32d-960f004aa19a",
   "metadata": {
    "id": "1f88c4cb-5512-4628-b32d-960f004aa19a"
   },
   "outputs": [],
   "source": [
    "new_text = df.loc[130,\"abstract\"][:-1] + '}' + df.loc[130,\"abstract\"][-1:] # In the text miss a graph parentesis\n",
    "\n",
    "# Update the DataFrame\n",
    "df.loc[130, \"abstract\"] = new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9b0067-f9b2-4ccf-8028-88ac89108ec5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0f9b0067-f9b2-4ccf-8028-88ac89108ec5",
    "outputId": "73d9b373-0953-4250-e430-e9161abee197"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of abstracts containing at least one formula: 26236 out of 200094\n",
      "Total number of extracted formulas: 182900\n"
     ]
    }
   ],
   "source": [
    "def extract_latex_formulas(text):\n",
    "    \"\"\"\n",
    "    Extracts LaTeX mathematical formulas from a given text.\n",
    "\n",
    "    This function identifies and extracts text segments that represent LaTeX-formatted\n",
    "    mathematical expressions. It covers the four most common types of formula delimiters:\n",
    "\n",
    "    - Inline formulas: enclosed by single dollar signs `$...$`\n",
    "    - Display formulas: enclosed by double dollar signs `$$...$$`\n",
    "    - Equation environment: `\\begin{equation}...\\end{equation}`\n",
    "    - Align environment: `\\begin{align}...\\end{align}`\n",
    "\n",
    "    Args:\n",
    "        text (str): The input string, a scientific abstract.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of strings, each representing LaTeX formulas found in the text.\n",
    "    \"\"\"\n",
    "    # $$...$$\n",
    "    display_pattern = re.findall(r'\\$\\$[^$].*?\\$\\$', text, flags=re.DOTALL)\n",
    "\n",
    "    # $...$\n",
    "    inline_pattern = re.findall(r'\\$[^$][^$\\n]*?\\$', text, flags=re.DOTALL)\n",
    "\n",
    "    # \\( ... \\)\n",
    "    text = re.sub(r'\\\\\\((.*?)\\\\\\)', '[FORMULA]', text)\n",
    "\n",
    "    # \\[...\\]\n",
    "    text = re.sub(r'\\\\\\[(.*?)\\\\\\]', '[FORMULA]', text)\n",
    "\n",
    "    # Equation environment: \\begin{equation}...\\end{equation}\n",
    "    equation_pattern = re.findall(r'\\\\begin{equation}.*?\\\\end{equation}', text, flags=re.DOTALL)\n",
    "\n",
    "    # align environment: \\begin{align}...\\end{align}\n",
    "    align_pattern = re.findall(r'\\\\begin{align}.*?\\\\end{align}', text, flags=re.DOTALL)\n",
    "\n",
    "    return inline_pattern + display_pattern + equation_pattern + align_pattern\n",
    "\n",
    "# Apply the function to each abstract in the dataset\n",
    "row_formulas = df['abstract'].apply(extract_latex_formulas)\n",
    "\n",
    "# Count how many abstracts contain at least one LaTeX formula\n",
    "num_with_formulas = row_formulas.apply(len).gt(0).sum()\n",
    "print(f\"Number of abstracts containing at least one formula: {num_with_formulas} out of {len(df)}\")\n",
    "\n",
    "# Flatten the list of lists to get all formulas across all abstracts\n",
    "all_formulas = [formula for sublist in row_formulas for formula in sublist]\n",
    "\n",
    "print(f\"Total number of extracted formulas: {len(all_formulas)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c93fae8-1088-4967-bc5b-eddff15aa51c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0c93fae8-1088-4967-bc5b-eddff15aa51c",
    "outputId": "1c8f4545-9e83-4469-f9cc-f85924ff4cf2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of abstracts still containing formulas after cleaning: 0 out of 200094\n"
     ]
    }
   ],
   "source": [
    "def replace_latex_formulas(text):\n",
    "    \"\"\"\n",
    "    Replaces all LaTeX mathematical formulas within a text with a placeholder token.\n",
    "\n",
    "    This function detects LaTeX-formatted formulas written in one of the following formats:\n",
    "\n",
    "    - Inline formulas: `$...$`\n",
    "    - Display formulas: `$$...$$`\n",
    "    - LaTeX environments: `\\begin{equation}...\\end{equation}` and `\\begin{align}...\\end{align}`\n",
    "\n",
    "    Each formula is replaced with the string `[FORMULA]` to simplify downstream text processing.\n",
    "    The use of `re.DOTALL` allows matching across multiple lines, which is necessary for\n",
    "    environments that may span several lines of text.\n",
    "\n",
    "    Returns:\n",
    "        str: A cleaned version of the input text with formulas replaced by [FORMULA].\n",
    "    \"\"\"\n",
    "\n",
    "    # Replace display formulas: $$...$$\n",
    "    text = re.sub(r'\\$\\$[^$].*?\\$\\$', \"[FORMULA]\", text, flags=re.DOTALL)\n",
    "\n",
    "    # Replace inline formulas: $...$\n",
    "    text = re.sub(r'\\$[^$][^$\\n]*?\\$', \"[FORMULA]\", text, flags=re.DOTALL)\n",
    "\n",
    "    # Inline math: \\( ... \\)\n",
    "    text = re.sub(r'\\\\\\((.*?)\\\\\\)', '[FORMULA]', text)\n",
    "\n",
    "    # Display math: \\[...\\]\n",
    "    text = re.sub(r'\\\\\\[(.*?)\\\\\\]', '[FORMULA]', text)\n",
    "\n",
    "    # Replace equation environment: \\begin{equation}...\\end{equation}\n",
    "    text = re.sub(r\"\\\\begin{equation}.*?\\\\end{equation}\", \"[FORMULA]\", text, flags=re.DOTALL)\n",
    "\n",
    "    # Replace align environment: \\begin{align}...\\end{align}\n",
    "    text = re.sub(r\"\\\\begin{align}.*?\\\\end{align}\", \"[FORMULA]\", text, flags=re.DOTALL)\n",
    "\n",
    "    return text\n",
    "\n",
    "# Apply formula replacement to the 'abstract' column\n",
    "df['abstract_clean'] = df['abstract'].apply(replace_latex_formulas)\n",
    "\n",
    "# Re-check if any LaTeX formulas remain after cleaning\n",
    "row_formulas = df['abstract_clean'].apply(extract_latex_formulas)\n",
    "\n",
    "# Count how many cleaned abstracts still contain LaTeX formulas (ideally should be 0)\n",
    "num_con_formulas = row_formulas.apply(len).gt(0).sum()\n",
    "print(f\"Number of abstracts still containing formulas after cleaning: {num_con_formulas} out of {len(df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c879784-4d2e-479d-ad8a-7aff13324a68",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5c879784-4d2e-479d-ad8a-7aff13324a68",
    "outputId": "d25ddde7-b958-4809-bda9-167e08a37f13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstracts with at least one link: 5311 out of 200094\n",
      "Total number of links extracted: 6036\n"
     ]
    }
   ],
   "source": [
    "def extract_latex_links(text):\n",
    "    r\"\"\"\n",
    "    Extracts all hyperlinks from a LaTeX-formatted text, including:\n",
    "\n",
    "    - \\url{...}\n",
    "    - \\href{URL}{label}\n",
    "    - Direct URLs starting with http or https\n",
    "\n",
    "    Returns:\n",
    "        list of str: A list of all link occurrences found in the input text.\n",
    "    \"\"\"\n",
    "    # Match \\href{url}{text}\n",
    "    href_links = re.findall(r'\\\\ref\\{[^}]*\\}', text)\n",
    "\n",
    "    # Match \\url{...}\n",
    "    latex_links = re.findall(r'\\\\url\\{[^}]*\\}', text)\n",
    "\n",
    "    # Match direct links like https://...\n",
    "    direct_links = re.findall(r'https?://[^\\s{}()\\[\\],;]+', text)\n",
    "\n",
    "    return latex_links + direct_links + href_links\n",
    "\n",
    "# Apply link extraction to each abstract\n",
    "row_links = df['abstract_clean'].apply(extract_latex_links)\n",
    "\n",
    "# Count number of abstracts containing at least one link\n",
    "num_con_links = row_links.apply(len).gt(0).sum()\n",
    "print(f\"Abstracts with at least one link: {num_con_links} out of {len(df)}\")\n",
    "\n",
    "# Flatten all links into a single list\n",
    "all_links = [link for sublist in row_links for link in sublist]\n",
    "print(f\"Total number of links extracted: {len(all_links)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fa082c-4f2f-4785-a91a-f69a52171493",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "26fa082c-4f2f-4785-a91a-f69a52171493",
    "outputId": "146940ef-eae7-4a0d-ba86-a1ccfb989feb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstracts with at least one link: 0 out of 200094\n"
     ]
    }
   ],
   "source": [
    "def replace_latex_links(text):\n",
    "    r\"\"\"\n",
    "    Replaces all hyperlinks in LaTeX format or raw URLs with a placeholder [LINK].\n",
    "\n",
    "    Handles:\n",
    "    - \\href{URL}{label}\n",
    "    - \\url{URL}\n",
    "    - Direct links (http:// or https://)\n",
    "\n",
    "    Returns:\n",
    "        str: The input text with links replaced.\n",
    "    \"\"\"\n",
    "    # Replace \\href{url}{label} with [LINK]\n",
    "    text = re.sub(r'\\\\ref\\{[^}]*\\}', '[LINK]', text)\n",
    "\n",
    "    # Replace \\url{...} with [LINK]\n",
    "    text = re.sub(r'\\\\url\\{[^}]*\\}', '[LINK]', text)\n",
    "\n",
    "    # Replace direct links (http:// or https://) with [LINK]\n",
    "    text = re.sub(r'https?://[^\\s{}()\\[\\],;]+', '[LINK]', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "# Apply the link removal to all abstracts\n",
    "df['abstract_clean'] = df['abstract_clean'].apply(replace_latex_links)\n",
    "\n",
    "# Check how many abstracts still contain links (should be 0 ideally)\n",
    "row_links = df['abstract_clean'].apply(extract_latex_links)\n",
    "num_con_links = row_links.apply(len).gt(0).sum()\n",
    "\n",
    "print(f\"Abstracts with at least one link: {num_con_links} out of {len(df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56ba209-502a-4ecb-bbcc-ee284286de79",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e56ba209-502a-4ecb-bbcc-ee284286de79",
    "outputId": "4cc25499-607c-415b-e5cb-c144d6f3666f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstracts containing '--': 8502 out of 200094\n"
     ]
    }
   ],
   "source": [
    "def extract_latex_bars(text):\n",
    "    \"\"\"\n",
    "    Extract all occurrences of double hyphens '--' from the input text.\n",
    "\n",
    "    Returns:\n",
    "        list: A list containing all instances of double hyphens found in the text.\n",
    "    \"\"\"\n",
    "    # Use regex to find all occurrences of '--' in the text\n",
    "    return re.findall(r'--', text)\n",
    "\n",
    "# Apply the extraction function to the 'abstract_clean' column of the DataFrame\n",
    "row_bars = df['abstract_clean'].apply(extract_latex_bars)\n",
    "\n",
    "# Count how many abstracts contain at least one double hyphen\n",
    "num_with_bars = row_bars.apply(len).gt(0).sum()\n",
    "\n",
    "print(f\"Abstracts containing '--': {num_with_bars} out of {len(df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1a0d71-5274-4bee-908f-81d0435a1d1b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8a1a0d71-5274-4bee-908f-81d0435a1d1b",
    "outputId": "640c7074-21e6-4ea8-ead2-be5fc5b24f2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstracts containing '--': 0 out of 200094\n"
     ]
    }
   ],
   "source": [
    "def replace_latex_bars(text):\n",
    "    \"\"\"\n",
    "    Replace all occurrences of double hyphens '--' with commas ','.\n",
    "\n",
    "    Args:\n",
    "        text (str): Input string possibly containing '--'.\n",
    "\n",
    "    Returns:\n",
    "        str: Modified string with '--' replaced by ','.\n",
    "    \"\"\"\n",
    "    return re.sub(r'--', ',', text)\n",
    "\n",
    "# Apply the replacement to the 'abstract_clean' column\n",
    "df['abstract_clean'] = df['abstract_clean'].apply(replace_latex_bars)\n",
    "\n",
    "# Apply the extraction function to the 'abstract_clean' column of the DataFrame\n",
    "row_bars = df['abstract_clean'].apply(extract_latex_bars)\n",
    "\n",
    "# Count how many abstracts contain at least one double hyphen\n",
    "num_with_bars = row_bars.apply(len).gt(0).sum()\n",
    "\n",
    "print(f\"Abstracts containing '--': {num_with_bars} out of {len(df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382f5ad6-4218-4cf3-8025-cd2124884044",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "382f5ad6-4218-4cf3-8025-cd2124884044",
    "outputId": "8d151aeb-7b94-403d-9871-2ca3834be4d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstracts with at least one bullet list: 10 out of 200094\n",
      "Total number of bullet list commands extracted: 10\n"
     ]
    }
   ],
   "source": [
    "def extract_latex_bullets_lists(text):\n",
    "    \"\"\"\n",
    "    Extract LaTeX bullet list commands from the input text.\n",
    "\n",
    "    Specifically matches the LaTeX environment start for itemized lists: \\begin{itemize}.\n",
    "\n",
    "\n",
    "    Returns\n",
    "        list: A list of all occurrences of the itemized list opening command.\n",
    "    \"\"\"\n",
    "    # Match occurrences of the LaTeX itemize environment opening\n",
    "    return re.findall(r'\\\\begin\\{itemize\\}', text)\n",
    "\n",
    "# Apply the extraction function to the 'abstract_clean' column\n",
    "row_bullets_lists = df['abstract_clean'].apply(extract_latex_bullets_lists)\n",
    "\n",
    "# Count how many abstracts contain at least one bullet list\n",
    "num_with_bullets = row_bullets_lists.apply(len).gt(0).sum()\n",
    "print(f\"Abstracts with at least one bullet list: {num_with_bullets} out of {len(df)}\")\n",
    "\n",
    "# Flatten the list to obtain all extracted bullet list commands\n",
    "all_bullets_lists = [cmd for sublist in row_bullets_lists for cmd in sublist]\n",
    "print(f\"Total number of bullet list commands extracted: {len(all_bullets_lists)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad27774-5f46-49b8-9fff-122d5607aa5e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bad27774-5f46-49b8-9fff-122d5607aa5e",
    "outputId": "e9d4660a-5fc1-4acd-b971-7aa3b70d7757"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstracts with at least one bullet list command: 0 out of 200094\n"
     ]
    }
   ],
   "source": [
    "def replace_latex_bullets_lists(text):\n",
    "    r\"\"\"\n",
    "    Removes LaTeX bullet list commands from the input text.\n",
    "\n",
    "    Specifically removes:\n",
    "    - \\begin{itemize}\n",
    "    - \\end{itemize}\n",
    "    - \\item\n",
    "\n",
    "\n",
    "    Returns\n",
    "        str: The cleaned string without LaTeX list formatting.\n",
    "    \"\"\"\n",
    "    text = re.sub(r'\\\\begin\\{itemize\\}', '', text)\n",
    "    text = re.sub(r'\\\\end\\{itemize\\}', '', text)\n",
    "    text = re.sub(r'\\\\item', '', text)\n",
    "    return text\n",
    "\n",
    "# Apply the replacement function to the dataset\n",
    "df['abstract_clean'] = df['abstract_clean'].apply(replace_latex_bullets_lists)\n",
    "\n",
    "# Re-check for any remaining bullet list commands\n",
    "row_bullets_lists = df['abstract_clean'].apply(extract_latex_bullets_lists)\n",
    "num_with_bullets = row_bullets_lists.apply(len).gt(0).sum()\n",
    "\n",
    "print(f\"Abstracts with at least one bullet list command: {num_with_bullets} out of {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41207692-f8ae-4a08-b720-ac6847e71f04",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "41207692-f8ae-4a08-b720-ac6847e71f04",
    "outputId": "e66c1efc-3106-4e55-d4b5-e0a987106298"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstracts with at least one backslash: 14375 out of 200094\n",
      "Total number of backslashes extracted: 33798\n"
     ]
    }
   ],
   "source": [
    "def extract_latex_backslash(text):\n",
    "    \"\"\"\n",
    "    Extracts all backslashes from the input text.\n",
    "\n",
    "    Backslashes are used to indicate LaTeX commands and escape sequences.\n",
    "\n",
    "    Returns\n",
    "        list: A list of all backslashes found in the text.\n",
    "    \"\"\"\n",
    "    return re.findall(r\"\\\\\", text)\n",
    "\n",
    "# Apply the extraction function to each abstract\n",
    "row_backslash = df['abstract_clean'].apply(extract_latex_backslash)\n",
    "\n",
    "# Count how many abstracts still contain at least one backslash\n",
    "num_with_backslash = row_backslash.apply(len).gt(0).sum()\n",
    "print(f\"Abstracts with at least one backslash: {num_with_backslash} out of {len(df)}\")\n",
    "\n",
    "# Flatten the list of all extracted backslashes\n",
    "all_backslash = [b for sublist in row_backslash for b in sublist]\n",
    "print(f\"Total number of backslashes extracted: {len(all_backslash)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fc67f5-0e00-4198-b62c-675675ea8a16",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "64fc67f5-0e00-4198-b62c-675675ea8a16",
    "outputId": "753b609f-bc16-41a3-a81a-3dd96d2066b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstracts with at least one backslash: 4668 out of 200094\n"
     ]
    }
   ],
   "source": [
    "def replace_latex_commands(text):\n",
    "    r\"\"\"\n",
    "    Cleans LaTeX-specific commands and replaces them with appropriate plain text equivalents.\n",
    "\n",
    "    Handles:\n",
    "    - \\emph{}, \\textit{}, \\textbf{}, \\underline{}: preserves the inner content\n",
    "    - \\em, \\cite{}: removes the command and/or content\n",
    "    - Replaces common LaTeX accented characters with Unicode equivalents\n",
    "\n",
    "    Returns\n",
    "        str: Text with LaTeX commands replaced or removed.\n",
    "    \"\"\"\n",
    "    # Preserve inner content for text formatting commands\n",
    "    text = re.sub(r'\\\\emph\\{([^}]+)\\}', r'\\1', text)\n",
    "    text = re.sub(r'\\\\textit\\{([^}]+)\\}', r'\\1', text)\n",
    "    text = re.sub(r'\\\\textbf\\{([^}]+)\\}', r'\\1', text)\n",
    "    text = re.sub(r'\\\\underline\\{([^}]+)\\}', r'\\1', text)\n",
    "\n",
    "    # Remove inline emphasis command (e.g., \\em text)\n",
    "    text = re.sub(r'\\\\em\\s*', '', text)\n",
    "\n",
    "    # Remove citation commands entirely\n",
    "    text = re.sub(r'\\\\cite\\{[^}]+\\}', '', text)\n",
    "\n",
    "    text = re.sub(r'\\\\colorb\\{([^}]*)\\}', r'\\1', text)\n",
    "\n",
    "    # Replace common LaTeX-encoded accented characters with Unicode equivalents\n",
    "    latex_accents = {\n",
    "        r\"\\\\'a\": \"á\", r\"\\\\'e\": \"é\", r\"\\\\'i\": \"í\", r\"\\\\'o\": \"ó\", r\"\\\\'u\": \"ú\",\n",
    "        r'\\\\\"a': \"ä\", r'\\\\\"e': \"ë\", r'\\\\\"i': \"ï\", r'\\\\\"o': \"ö\", r'\\\\\"u': \"ü\",\n",
    "        r\"\\\\`a\": \"à\", r\"\\\\`e\": \"è\", r\"\\\\`i\": \"ì\", r\"\\\\`o\": \"ò\", r\"\\\\`u\": \"ù\",\n",
    "        r\"\\\\^a\": \"â\", r\"\\\\^e\": \"ê\", r\"\\\\^i\": \"î\", r\"\\\\^o\": \"ô\", r\"\\\\^u\": \"û\",\n",
    "        r\"\\\\~n\": \"ñ\", r\"\\\\H\\{o\\}\": \"ő\", r\"\\\\H\\{u\\}\": \"ű\", r\"\\\\'{e}\": \"é\", r\"\\\\'{o}\": \"ó\",\n",
    "        r\"\\\\'{u}\": \"ú\", r\"\\\\'{i}\": \"í\", r\"\\\\'{a}\": \"á\",\n",
    "    }\n",
    "    for latex, replacement in latex_accents.items():\n",
    "        text = re.sub(latex, replacement, text)\n",
    "\n",
    "    replacements = {\n",
    "        r'\\\\#': '#',\n",
    "        r'\\\\%': '%',\n",
    "        r'\\\\&': '&',\n",
    "        r\"\\\\'\": \"'\",\n",
    "        r\"\\\\`\": \"`\",\n",
    "        r'\\\\~': \"~\",\n",
    "        r'\\\\\\^': \"^\"\n",
    "    }\n",
    "    for pattern, replacement in replacements.items():\n",
    "        text = re.sub(pattern, replacement, text)\n",
    "\n",
    "    return text\n",
    "\n",
    "# Apply the command replacement to each abstract\n",
    "df['abstract_clean'] = df['abstract_clean'].apply(replace_latex_commands)\n",
    "\n",
    "# Check for any remaining backslashes (indicating unresolved LaTeX commands)\n",
    "row_backslash = df['abstract_clean'].apply(extract_latex_backslash)\n",
    "num_con_commands = row_backslash.apply(len).gt(0).sum()\n",
    "\n",
    "print(f\"Abstracts with at least one backslash: {num_con_commands} out of {len(df)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee36ca2-14b6-4d60-a5a5-fb0b423534ef",
   "metadata": {
    "id": "cee36ca2-14b6-4d60-a5a5-fb0b423534ef"
   },
   "source": [
    "The row 15 present a special command \\\\model. By examining the original abstract, I found that the command takes the value DANLIP, and thus I proceed with its replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dcf0f6-df3b-404d-8af6-1d5d2f070ef4",
   "metadata": {
    "id": "b6dcf0f6-df3b-404d-8af6-1d5d2f070ef4"
   },
   "outputs": [],
   "source": [
    "df.loc[15, 'abstract_clean'] = df.loc[15, 'abstract_clean'].replace(r\"\\model\", \"DANLIP\")\n",
    "\n",
    "df.loc[9819, 'abstract_clean'] = df.loc[15, 'abstract_clean'].replace(r\"\\method\", \"TopoImb\")\n",
    "\n",
    "df.loc[10209, 'abstract_clean'] = df.loc[15, 'abstract_clean'].replace(r\"\\model\", \"LSM\")\n",
    "\n",
    "df.loc[10366, 'abstract_clean'] = df.loc[15, 'abstract_clean'].replace(r\"\\ourmodel\", \"PHN-HVI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551efedb-fcb6-4777-9732-704e6e9279f0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "551efedb-fcb6-4777-9732-704e6e9279f0",
    "outputId": "1d382740-819a-4762-a568-b678d7831c2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstracts with at least one backslash: 2433 out of 200094\n"
     ]
    }
   ],
   "source": [
    "def clean_latex_commands(text):\n",
    "    \"\"\"\n",
    "    Cleans LaTeX markup and formatting from a scientific text string.\n",
    "\n",
    "    This function removes or replaces common LaTeX commands, special characters,\n",
    "    and formatting patterns to produce clean, plain text suitable for NLP tasks.\n",
    "\n",
    "    Returns:\n",
    "        str: The cleaned version of the input string, with LaTeX commands stripped or replaced.\n",
    "    \"\"\"\n",
    "    # 1. Remove LaTeX commands that include arguments in braces, e.g., \\citep{...}\n",
    "    commands_to_remove = ['citep', 'citet', 'footnote', 'color', 'mbox','cite']\n",
    "    for cmd in commands_to_remove:\n",
    "        text = re.sub(rf'\\\\{cmd}\\{{[^}}]*\\}}', '', text)\n",
    "\n",
    "    # 2. Unwrap commands like \\texttt{word} → word\n",
    "    unwrap_commands = ['texttt', 'textsc', 'textsf', 'textsl', 'ul', 'gls', 'glspl', 'uline', 'revision']\n",
    "    for cmd in unwrap_commands:\n",
    "        text = re.sub(rf'\\\\{cmd}\\{{([^}}]*)\\}}', r'\\1', text)\n",
    "\n",
    "    # 3. Replace common LaTeX shortcuts or symbols\n",
    "    replacements = {\n",
    "        r'\\\\deg': '°',\n",
    "        r'\\\\eps\\b': 'ε',\n",
    "        r'\\\\ie\\b': 'i.e.',\n",
    "        r'\\\\eg\\b': 'e.g.',\n",
    "        r'\\\\iid\\b': 'i.i.d.',\n",
    "        r'\\\\\"{o}': 'ó',\n",
    "        r'\\\\ll\\b': '≪',\n",
    "        r'\\\\dots(?=\\w)': '',       # \\dotsword → word\n",
    "        r'~\\\\ie\\b': 'i.e.',\n",
    "        r'\\\\ell': 'ell',\n",
    "    }\n",
    "    for pattern, repl in replacements.items():\n",
    "        text = re.sub(pattern, repl, text)\n",
    "\n",
    "    # 4. Replace escaped special characters\n",
    "    escapes = {\n",
    "        r'\\\\\\$': '$',\n",
    "        r'\\\\_': '_',\n",
    "        r'\\\\,': ' ',\n",
    "        r'\\\\:': ':',\n",
    "        r'\\\\2': '2',\n",
    "        r'\\\\c': 'c',\n",
    "        r'\\\\t': 't',\n",
    "        r'\\\\P': 'P',\n",
    "    }\n",
    "    for pattern, repl in escapes.items():\n",
    "        text = re.sub(pattern, repl, text)\n",
    "\n",
    "    # 5. Handle accented letters and special encodings\n",
    "    text = re.sub(r'na\\\\\"\\{i\\}ve', 'naïve', text)\n",
    "    text = re.sub(r'\\\\v\\{a\\}', 'ǎ', text)\n",
    "    text = re.sub(r'\\\\k\\{([^}]+)\\}', r'k\\1', text)\n",
    "\n",
    "    # 6. Unwrap grouped formatting, e.g., {\\bf text} → text\n",
    "    text = re.sub(r'\\{\\\\[a-z]+\\s*([^}]+)\\}', r'\\1', text)\n",
    "\n",
    "    # 7. Remove unwanted standalone LaTeX commands\n",
    "    text = re.sub(r'\\\\(s|indent)\\b', '', text)\n",
    "\n",
    "    # 8. Replace hyperlink-style commands with a placeholder\n",
    "    text = re.sub(r'\\\\href\\s*\\{[^}]*\\}\\{[^}]*\\}', '[LINK]', text)\n",
    "    text = re.sub(r'\\\\hyperlink\\{[^}]*\\}\\{[^}]*\\}', '', text)\n",
    "\n",
    "    # 9. Replace double backslashes with a single space\n",
    "    text = re.sub(r'\\\\\\\\\\s*', ' ', text)\n",
    "\n",
    "    # 10. Replace known formula pattern with [FORMULA]\n",
    "    # text = re.sub(r\"P\\(\\|In - I\\* \\| {\\leq} {delta}I\\*\\) {\\leq}\", \"[FORMULA]\", text)\n",
    "    text = re.sub(\"P\\\\(\\\\|In - I\\\\* \\\\| \\\\{\\\\\\\\leq\\\\} \\\\{delta\\\\}I\\\\*\\\\) \\\\{\\\\\\\\leq\\\\}\", \"[FORMULA]\", text)\n",
    "\n",
    "\n",
    "    return text\n",
    "\n",
    "# Apply the command replacement to each abstract\n",
    "df['abstract_clean'] = df['abstract_clean'].apply(clean_latex_commands)\n",
    "\n",
    "# Check for any remaining backslashes (indicating unresolved LaTeX commands)\n",
    "row_backslash = df['abstract_clean'].apply(extract_latex_backslash)\n",
    "num_con_commands = row_backslash.apply(len).gt(0).sum()\n",
    "\n",
    "print(f\"Abstracts with at least one backslash: {num_con_commands} out of {len(df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4d4276-6be8-47ae-9b38-b94e2aecd00c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6d4d4276-6be8-47ae-9b38-b94e2aecd00c",
    "outputId": "f2fabdea-5320-46f1-f8ea-3174b7271e36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ROW 18418] Error during LaTeX conversion: list index out of range\n",
      "[ROW 127553] Error during LaTeX conversion: list index out of range\n",
      "Abstracts with at least one backslash: 0 out of 200094\n",
      "Total number of backslashes extracted: 0\n"
     ]
    }
   ],
   "source": [
    "error_indices = []\n",
    "\n",
    "def latex_to_plain_with_logging(text, idx=None):\n",
    "    \"\"\"\n",
    "    Converts a LaTeX formatted string into plain text while logging any conversion errors.\n",
    "\n",
    "    Returns:\n",
    "        str: The plain text version of the input string. If an error occurs, returns an empty string.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    try:\n",
    "        # Convert LaTeX to plain text\n",
    "        return LatexNodes2Text().latex_to_text(text)\n",
    "    except Exception as e:\n",
    "        # Log any errors along with the index of the problematic row\n",
    "        print(f\"[ROW {idx}] Error during LaTeX conversion: {e}\")\n",
    "        error_indices.append(idx)\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "# Apply conversion to all rows in the abstract_clean column\n",
    "df[\"plain_abstract\"] = [\n",
    "    latex_to_plain_with_logging(text, idx) for idx, text in enumerate(df[\"abstract_clean\"])\n",
    "]\n",
    "\n",
    "# Detect remaining LaTeX-style backslashes in the cleaned abstracts\n",
    "row_backslash = df['plain_abstract'].apply(extract_latex_backslash)\n",
    "\n",
    "# Count how many abstracts still contain at least one backslash\n",
    "num_with_backslash = row_backslash.apply(len).gt(0).sum()\n",
    "print(f\"Abstracts with at least one backslash: {num_with_backslash} out of {len(df)}\")\n",
    "\n",
    "# Flatten all backslashes into a single list\n",
    "all_backslash = [b for sublist in row_backslash for b in sublist]\n",
    "print(f\"Total number of backslashes extracted: {len(all_backslash)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WMAskHOVBGDS",
   "metadata": {
    "id": "WMAskHOVBGDS"
   },
   "outputs": [],
   "source": [
    "# Righe da modificare (0-based index, quindi 18547 e 126999)\n",
    "target_rows = [18418, 127553]\n",
    "\n",
    "# Funzione di pulizia\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    text = re.sub(r'\\$.*?\\$', '[FORMULA]', text)\n",
    "    text = re.sub(r'\\\\mathbb\\{.*?\\}', '[FORMULA]', text)\n",
    "    text = re.sub(r'\\\\href\\{.*?\\}\\ \\{.*?\\}', '[LINK]', text)\n",
    "    text = re.sub(r'\\\\href\\{[^}]*\\}', '[LINK]', text)\n",
    "    return text\n",
    "\n",
    "# Applica solo alle righe selezionate (su tutte le colonne testuali)\n",
    "for row in target_rows:\n",
    "        df.at[row, \"plain_abstract\"] = clean_text(df.at[row, \"abstract_clean\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c252e9-c180-4d48-be01-1fa6d426a201",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "id": "c3c252e9-c180-4d48-be01-1fa6d426a201",
    "outputId": "8e0b3e9f-4b80-4c89-d29e-0291b5e44ce0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Training graph neural networks (GNNs) on large graphs is complex and extremely time consuming. This is attributed to overheads caused by sparse matrix multiplication, which are sidestepped when training multi-layer perceptrons (MLPs) with only node features. MLPs, by ignoring graph context, are simple and faster for graph data, however they usually sacrifice prediction accuracy, limiting their applications for graph data. We observe that for most message passing-based GNNs, we can trivially derive an analog MLP (we call this a PeerMLP) with an equivalent weight space, by setting the trainable parameters with the same shapes, making us curious about how do GNNs using weights from a fully trained PeerMLP perform? Surprisingly, we find that GNNs initialized with such weights significantly outperform their PeerMLPs, motivating us to use PeerMLP training as a precursor, initialization step to GNN training. To this end, we propose an embarrassingly simple, yet hugely effective initialization method for GNN training acceleration, called MLPInit. Our extensive experiments on multiple large-scale graph datasets with diverse GNN architectures validate that MLPInit can accelerate the training of GNNs (up to 33X speedup on OGB-Products) and often improve prediction performance (e.g., up to [FORMULA] improvement for GraphSAGE across [FORMULA] datasets for node classification, and up to [FORMULA] improvement across [FORMULA] datasets for link prediction on metric Hits@10). The code is available at [LINK].'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[127553, \"plain_abstract\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25328a9-d6eb-4084-ba4b-3a3ffbb6dc3c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "id": "a25328a9-d6eb-4084-ba4b-3a3ffbb6dc3c",
    "outputId": "5a3d1d9a-27e7-42b0-b55d-b3cd23c645c3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Training graph neural networks (GNNs) on large graphs is complex and extremely time consuming. This is attributed to overheads caused by sparse matrix multiplication, which are sidestepped when training multi-layer perceptrons (MLPs) with only node features. MLPs, by ignoring graph context, are simple and faster for graph data, however they usually sacrifice prediction accuracy, limiting their applications for graph data. We observe that for most message passing-based GNNs, we can trivially derive an analog MLP (we call this a PeerMLP) with an equivalent weight space, by setting the trainable parameters with the same shapes, making us curious about how do GNNs using weights from a fully trained PeerMLP perform? Surprisingly, we find that GNNs initialized with such weights significantly outperform their PeerMLPs, motivating us to use PeerMLP training as a precursor, initialization step to GNN training. To this end, we propose an embarrassingly simple, yet hugely effective initialization method for GNN training acceleration, called MLPInit. Our extensive experiments on multiple large-scale graph datasets with diverse GNN architectures validate that MLPInit can accelerate the training of GNNs (up to 33X speedup on OGB-Products) and often improve prediction performance (e.g., up to [FORMULA] improvement for GraphSAGE across [FORMULA] datasets for node classification, and up to [FORMULA] improvement across [FORMULA] datasets for link prediction on metric Hits@10). The code is available at \\\\href{[LINK]}.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[127553, \"abstract_clean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f6817c-d9e6-45ae-9b12-cfe8d50e7465",
   "metadata": {
    "id": "76f6817c-d9e6-45ae-9b12-cfe8d50e7465"
   },
   "outputs": [],
   "source": [
    "df[\"abstract_clean\"] = df[\"plain_abstract\"]\n",
    "\n",
    "df = df.drop(\"plain_abstract\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Jb-OOh2VOh9C",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 651
    },
    "id": "Jb-OOh2VOh9C",
    "outputId": "9e5c42ab-80a2-49ac-e966-4f0233952851"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    200094.000000\n",
      "mean        200.287460\n",
      "std          76.802537\n",
      "min           3.000000\n",
      "25%         147.000000\n",
      "50%         195.000000\n",
      "75%         247.000000\n",
      "max         767.000000\n",
      "Name: abstract, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def separate_tokens(text):\n",
    "    # Insert spaces around punctuation characters\n",
    "    text = re.sub(r'([^\\w\\s])', r' \\1 ', str(text))\n",
    "    # Replace multiple spaces with a single space\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "# Apply token separation on the 'abstract' column\n",
    "abstract_preprocessed = df['abstract_clean'].apply(separate_tokens)\n",
    "\n",
    "# Calculate number of tokens per abstract (including punctuation)\n",
    "abstract_length = abstract_preprocessed.apply(lambda x: len(x.split()))\n",
    "\n",
    "\n",
    "# Plot boxplot of abstract lengths\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.boxplot(x=abstract_length, color='lightblue')\n",
    "plt.title('Boxplot of Abstract Lengths (Words + Separated Punctuation)')\n",
    "plt.xlabel('Number of Tokens')\n",
    "\n",
    "plt.savefig('length_abstract.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Display summary statistics\n",
    "print(abstract_length.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40fbc6a-6267-4e23-a1ad-dc66ddfc25f7",
   "metadata": {
    "id": "b40fbc6a-6267-4e23-a1ad-dc66ddfc25f7"
   },
   "outputs": [],
   "source": [
    "save_path = '../Datasets/cleaned_dataset.csv'\n",
    "\n",
    "# Salva il CSV\n",
    "df.to_csv(save_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
